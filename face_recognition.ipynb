{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Face Recognition using Face Images obtained from the internet**\n",
    "The objective of this project is to implement an accurate face recognition model for a custom dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common\n",
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from IPython.display import clear_output as cls\n",
    "\n",
    "# Data \n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "\n",
    "# Data Visuaalization\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a random\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define the image dimensions\n",
    "IMG_W, IMG_H, IMG_C = (112, 112, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Loading**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of individuals: 250\n",
      "\n",
      "Name of the individuals : \n",
      "\t['aaron_finch', 'abhay_deol', 'adam_zampa', 'adil_hussain', 'adil_rashid', 'ajay_devgn', 'akshaye_khanna', 'akshay_kumar', 'alex_carey', 'amitabh_bachchan', 'amjad_khan', 'amole_gupte', 'amol_palekar', 'amrish_puri', 'andre_russell', 'angelo_mathews', 'anil_kapoor', 'annu_kapoor', 'anrich_nortje', 'anupam_kher', 'anushka_shetty', 'arshad_warsi', 'aruna_irani', 'ashish_vidyarthi', 'asrani', 'Associate_Prof_Chester_Rebeiro', 'Associate_prof_LA_Prashanth', 'Associate_Prof_Manikandan_Narayanan', 'Associate_prof_Meghana_Nasre', 'Associate_prof_Raghavendra_Rao', 'Associate_Prof_Rupesh_Nasre', 'Asst_prof_Aishwarya_Thiruvengadam', 'Asst_prof_Arun_Rajkumar', 'Asst_prof_Ayon_Chakraborty', 'Asst_prof_Chandrashekar_Lakshminarayanan', 'Asst_Prof_Harish_Guruprasad', 'Asst_prof_Kartik_Nagar', 'Asst_Prof_Mitesh_Khapra', 'Asst_prof_Nishad_Kothari', 'Asst_Prof_Yadu_Vasudev', 'atul_kulkarni', 'avishka_fernando', 'ayushmann_khurrana', 'babar_azam', 'ben_stokes', 'bhuvneshwar_kumar', 'boman_irani', 'chiranjeevi', 'chris_morris', 'chunky_panday', 'dale_steyn', 'danny_denzongpa', 'darsheel_safary', 'David_Peleg', 'david_warner', 'Deepak_Padmanabhan', 'deepika_padukone', 'deepti_naval', 'dev_anand', 'dharmendra', 'dilip_kumar', 'dimple_kapadia', 'dinesh_karthik', 'DrShweta_Agarwal', 'Dr_Akansha_Agarwal', 'eoin_morgan', 'faf_du_plessis', 'fakhar_zaman', 'farhan_akhtar', 'farida_jalal', 'farooq_shaikh', 'girish_karnad', 'Gopal_Pandurangan', 'govinda', 'gulbadin_naib', 'gulshan_grover', 'hardik_pandya', 'hrithik_roshan', 'huma_qureshi', 'imam-ul-haq', 'irrfan_khan', 'isuru_udana', 'jason_behrendorff', 'jason_holder', 'jason_roy', 'jaspal_bhatti', 'jasprit_bumrah', 'jeetendra', 'jeevan_mendis', 'jimmy_sheirgill', 'joe_root', 'johnny_lever', 'jonny_bairstow', 'jos_buttler', 'jp_duminy', 'kader_khan', 'kajol', 'kalki_koechlin', 'kamal_haasan', 'kane_williamson', 'kangana_ranaut', 'kay_kay_menon', 'kedar_jadhav', 'kemar_roach', 'konkona_sen_sharma', 'kulbhushan_kharbanda', 'kuldeep_yadav', 'kusal_perera', 'k_l_rahul', 'lara_dutta', 'lasith_malinga', 'lungi_ngidi', 'madhavan', 'madhuri_dixit', 'Madhu_Muthyam', 'mammootty', 'Manikantan_Srinivasan', 'manoj_bajpayee', 'manoj_pahwa', 'marcus_stoinis', 'mehmood', 'mita_vashisht', 'mitchell_starc', 'mithun_chakraborty', 'moeen_ali', 'mohammad_hafeez', 'mohammed_shami', 'mohanlal', 'mohnish_bahl', 'Mriganka_sur', 'ms_dhoni', 'mujeeb_ur_rahman', 'mukesh_khanna', 'mukul_dev', 'mushfiqur_rahim', 'nagarjuna_akkineni', 'nana_patekar', 'nandita_das', 'nargis', 'naseeruddin_shah', 'nathan_coulter-nile', 'navin_nischol', 'nawazuddin_siddiqui', 'neeraj_kabi', 'nicholas_pooran', 'nirupa_roy', 'om_puri', 'pankaj_kapur', 'pankaj_tripathi', 'paresh_rawal', 'Partha_Mitra', 'pat_cummins', 'pawan_malhotra', 'pooja_bhatt', 'prabhas', 'prabhu_deva', 'prakash_raj', 'pran', 'prem_chopra', 'priyanka_chopra', 'ProfSukhendu_Das', 'Prof_Anurag_Mittal', 'Prof_Balaraman_Ravindran', 'Prof_Chandra_Sekhar', 'Prof_D_Janakiram', 'Prof_Hema_Murthy', 'Prof_Jayalal_Sarma', 'Prof_John_Augustine', 'Prof_Krishna_Moorthy_Sivalingam', 'Prof_Krishna_Nandivada', 'Prof_NS_Narayanaswamy', 'Prof_Siva_Ram_Murthy', 'Prof_Srinivasa_kumar', 'Prof_Sutanu_Chakraborti', 'Prof_V_Kamakoti', 'quinton_de_kock', 'raaj_kumar', 'radhika_apte', 'rahul_bose', 'rajat_kapoor', 'rajesh_khanna', 'rajinikanth', 'rajit_kapoor', 'rajkummar_rao', 'rajpal_yadav', 'raj_babbar', 'raj_kapoor', 'rakhee_gulzar', 'ramya_krishnan', 'ranbir_kapoor', 'randeep_hooda', 'rani_mukerji', 'ranveer_singh', 'ranvir_shorey', 'rashid_khan', 'ratna_pathak_shah', 'ravindra_jadeja', 'rekha', 'richa_chadha', 'rishi_kapoor', 'riteish_deshmukh', 'rohit_sharma', 'ross_taylor', 'sachin_khedekar', 'saeed_jaffrey', 'saif_ali_khan', 'salman_khan', 'samiullah_shinwari', 'sanjay_dutt', 'sanjay_mishra', 'Sarath_Chandar', 'sarfaraz_ahmed', 'shabana_azmi', 'shadab_khan', 'shah_rukh_khan', 'shakib_al_hasan', 'sharman_joshi', 'sharmila_tagore', 'shashi_kapoor', 'shikhar_dhawan', 'shimron_hetmyer', 'shoaib_malik', 'shreyas_talpade', 'Shrikanth_Narayanan', 'smita_patil', 'soumitra_chatterjee', 'sridevi', 'Srinivas_Parthasarathy', 'Sriraam_Natarajan', 'steve_smith', 'sunil_shetty', 'sunny_deol', 'tabraiz_shamsi', 'tabu', 'thisara_perera', 'tinnu_anand', 'tom_curran', 'trent_boult', 'utpal_dutt', 'varun_dhawan', 'vidya_balan', 'Vijay_Raghunathan', 'vijay_shankar', 'vinod_khanna', 'virat_kohli', 'Vyas_Sekar', 'waheeda_rehman', 'yuzvendra_chahal', 'zarina_wahab', 'zeenat_aman']\n"
     ]
    }
   ],
   "source": [
    "# Specify the root directory path\n",
    "root_path = 'datasets/train/'\n",
    "\n",
    "# Collect all the person names\n",
    "dir_names = os.listdir(root_path)\n",
    "\n",
    "person_names = [name for name in dir_names]\n",
    "n_individuals = len(person_names)\n",
    "\n",
    "print(f\"Total number of individuals: {n_individuals}\\n\")\n",
    "print(f\"Name of the individuals : \\n\\t{person_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Images : 6683.\n"
     ]
    }
   ],
   "source": [
    "# Number of images available per person\n",
    "name = dir_names[0]\n",
    "\n",
    "n_images_per_person = [len(os.listdir(root_path + name)) for name in dir_names]\n",
    "n_images = sum(n_images_per_person)\n",
    "\n",
    "# Show\n",
    "print(f\"Total Number of Images : {n_images}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Distribution of number of images per person.\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.bar(person_names, n_images_per_person)\n",
    "plt.title(\"Distribution of number of images per person\")\n",
    "plt.xlabel(\"Person Name\")\n",
    "plt.ylabel(\"Number of Images\")\n",
    "plt.xticks('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all the file paths : 50 images per person.\n",
    "filepaths = [path  for name in dir_names for path in glob(root_path + name + '/*')[:50]]\n",
    "np.random.shuffle(filepaths)\n",
    "print(f\"Total number of images to be loaded : {len(filepaths)}\")\n",
    "\n",
    "# Create space for the images\n",
    "all_images = np.empty(shape=(len(filepaths), IMG_W, IMG_H, IMG_C), dtype = np.float32)\n",
    "all_labels = np.empty(shape=(len(filepaths), 1), dtype = np.int32)\n",
    "\n",
    "# For each path, load the image and apply some preprocessing.\n",
    "for index, path in enumerate(tqdm(filepaths)):\n",
    "    \n",
    "    # Extract label\n",
    "    label = [name for name in dir_names if name in path][0]\n",
    "    label = person_names.index(label)\n",
    "    \n",
    "    # Load the Image\n",
    "    image = plt.imread(path)\n",
    "    \n",
    "    # Resize the image\n",
    "    image = cv.resize(image, dsize = (IMG_W, IMG_H))\n",
    "    \n",
    "    # Convert image stype\n",
    "    image = image.astype(np.float32)/255.0\n",
    "    \n",
    "    # Store the image and the label\n",
    "    all_images[index] = image\n",
    "    all_labels[index] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Visualization**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(\n",
    "    images: np.ndarray, \n",
    "    labels: np.ndarray,\n",
    "    GRID: tuple=(15,6),\n",
    "    FIGSIZE: tuple=(25,50), \n",
    "    recog_fn = None,\n",
    "    database = None\n",
    ") -> None:\n",
    "\n",
    "    # Plotting Configuration\n",
    "    plt.figure(figsize=FIGSIZE)\n",
    "    n_rows, n_cols = GRID\n",
    "    n_images = n_rows * n_cols\n",
    "    \n",
    "    # loop over the images and labels\n",
    "    for index in range(n_images):\n",
    "        \n",
    "        # Select image in the corresponding label randomly\n",
    "        image_index = np.random.randint(len(images))\n",
    "        image, label = images[image_index], person_names[int(labels[image_index])]\n",
    "        \n",
    "        # Create a Subplot\n",
    "        plt.subplot(n_rows, n_cols, index+1)\n",
    "        \n",
    "        # Plot Image\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        if recog_fn is None:\n",
    "            # Plot title\n",
    "            plt.title(label)\n",
    "        else:\n",
    "            recognized = recog_fn(image, database)\n",
    "            plt.title(f\"True:{label}\\nPred:{recognized}\")\n",
    "    \n",
    "    # Show final Plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data(images = all_images, labels = all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Create Model**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.engine import training\n",
    "from tensorflow import keras\n",
    "from keras.layers import (\n",
    "    ZeroPadding2D,\n",
    "    Input,\n",
    "    Conv2D,\n",
    "    BatchNormalization,\n",
    "    PReLU,\n",
    "    Add,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Dense,\n",
    ")\n",
    "\n",
    "# Load the model\n",
    "def loadModel(file_path=\"arcface_weights.h\"):\n",
    "\n",
    "    base_model = ResNet34()\n",
    "    inputs = base_model.inputs[0]\n",
    "    arcface_model = base_model.outputs[0]\n",
    "    arcface_model = BatchNormalization(momentum=0.9, epsilon=2e-5)(arcface_model)\n",
    "    arcface_model = Dropout(0.4)(arcface_model)\n",
    "    arcface_model = Flatten()(arcface_model)\n",
    "    arcface_model = Dense(\n",
    "        512, activation=None, use_bias=True, kernel_initializer=\"glorot_normal\"\n",
    "    )(arcface_model)\n",
    "    embedding = BatchNormalization(\n",
    "        momentum=0.9, epsilon=2e-5, name=\"embedding\", scale=True\n",
    "    )(arcface_model)\n",
    "\n",
    "    # Create the model\n",
    "    model = keras.models.Model(inputs, embedding, name=base_model.name)\n",
    "\n",
    "    # Load the weights\n",
    "    model.load_weights(file_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def ResNet34():\n",
    "    img_input = Input(shape=(112, 112, 3))\n",
    "\n",
    "    x = ZeroPadding2D(padding=1, name=\"conv1_pad\")(img_input)\n",
    "    x = Conv2D(\n",
    "        64,\n",
    "        3,\n",
    "        strides=1,\n",
    "        use_bias=False,\n",
    "        kernel_initializer=\"glorot_normal\",\n",
    "        name=\"conv1_conv\",\n",
    "    )(x)\n",
    "    x = BatchNormalization(axis=3, epsilon=2e-5, momentum=0.9, name=\"conv1_bn\")(x)\n",
    "    x = PReLU(shared_axes=[1, 2], name=\"conv1_prelu\")(x)\n",
    "    x = stack_fn(x)\n",
    "\n",
    "    # Create model.\n",
    "    model = training.Model(img_input, x, name=\"ResNet34\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def block1(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\n",
    "    bn_axis = 3\n",
    "\n",
    "    # if conv_shortcut is True, apply convolutional layer to the shortcut\n",
    "    if conv_shortcut:\n",
    "        shortcut = Conv2D(\n",
    "            filters,\n",
    "            1,\n",
    "            strides=stride,\n",
    "            use_bias=False,\n",
    "            kernel_initializer=\"glorot_normal\",\n",
    "            name=name + \"_0_conv\",\n",
    "        )(x)\n",
    "        shortcut = BatchNormalization(\n",
    "            axis=bn_axis, epsilon=2e-5, momentum=0.9, name=name + \"_0_bn\"\n",
    "        )(shortcut)\n",
    "    else:\n",
    "        shortcut = x\n",
    "\n",
    "    x = BatchNormalization(\n",
    "        axis=bn_axis, epsilon=2e-5, momentum=0.9, name=name + \"_1_bn\"\n",
    "    )(x)\n",
    "    x = ZeroPadding2D(padding=1, name=name + \"_1_pad\")(x)\n",
    "    x = Conv2D(\n",
    "        filters,\n",
    "        3,\n",
    "        strides=1,\n",
    "        kernel_initializer=\"glorot_normal\",\n",
    "        use_bias=False,\n",
    "        name=name + \"_1_conv\",\n",
    "    )(x)\n",
    "    x = BatchNormalization(\n",
    "        axis=bn_axis, epsilon=2e-5, momentum=0.9, name=name + \"_2_bn\"\n",
    "    )(x)\n",
    "    x = PReLU(shared_axes=[1, 2], name=name + \"_1_prelu\")(x)\n",
    "\n",
    "    x = ZeroPadding2D(padding=1, name=name + \"_2_pad\")(x)\n",
    "    x = Conv2D(\n",
    "        filters,\n",
    "        kernel_size,\n",
    "        strides=stride,\n",
    "        kernel_initializer=\"glorot_normal\",\n",
    "        use_bias=False,\n",
    "        name=name + \"_2_conv\",\n",
    "    )(x)\n",
    "    x = BatchNormalization(\n",
    "        axis=bn_axis, epsilon=2e-5, momentum=0.9, name=name + \"_3_bn\"\n",
    "    )(x)\n",
    "\n",
    "    x = Add(name=name + \"_add\")([shortcut, x])\n",
    "    return x\n",
    "\n",
    "\n",
    "def stack1(x, filters, blocks, stride1=2, name=None):\n",
    "    x = block1(x, filters, stride=stride1, name=name + \"_block1\")\n",
    "    for i in range(2, blocks + 1):\n",
    "        x = block1(x, filters, conv_shortcut=False, name=name + \"_block\" + str(i))\n",
    "    return x\n",
    "\n",
    "\n",
    "def stack_fn(x):\n",
    "    x = stack1(x, 64, 3, name=\"conv2\")\n",
    "    x = stack1(x, 128, 4, name=\"conv3\")\n",
    "    x = stack1(x, 256, 6, name=\"conv4\")\n",
    "    return stack1(x, 512, 3, name=\"conv5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Face Database**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path: str, IMG_W: int = IMG_W, IMG_H: int = IMG_H) -> np.ndarray:    \n",
    "    # Load the image\n",
    "    image = plt.imread(image_path)\n",
    "    \n",
    "    # Resize the image\n",
    "    image = cv.resize(image, dsize=(IMG_W, IMG_H))\n",
    "    \n",
    "    # Convert image type and normalize pixel values\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "    \n",
    "    return image\n",
    "\n",
    "def image_to_embedding(image: np.ndarray, model) -> np.ndarray:\n",
    "    # Obtain image encoding\n",
    "    embedding = model.predict(image[np.newaxis,...], verbose=False)\n",
    "\n",
    "    # Normalize bedding using L2 norm.\n",
    "    embedding /= np.linalg.norm(embedding, ord=2)\n",
    "    \n",
    "    # Return embedding\n",
    "    return embedding\n",
    "    \n",
    "def generate_avg_embedding(image_paths: list, model) -> np.ndarray:    \n",
    "    # Collect embeddings\n",
    "    embeddings = np.empty(shape=(len(image_paths), 512))\n",
    "    \n",
    "    # Loop over images\n",
    "    for index, image_path in enumerate(image_paths):\n",
    "        \n",
    "        # Load the image\n",
    "        image = load_image(image_path)\n",
    "        \n",
    "        # Generate the embedding\n",
    "        embedding = image_to_embedding(image, model)\n",
    "        \n",
    "        # Store the embedding\n",
    "        embeddings[index] = embedding\n",
    "        \n",
    "    # Compute average embedding\n",
    "    avg_embedding = np.mean(embeddings, axis=0)\n",
    "    \n",
    "    # Clear Output\n",
    "    # cls()\n",
    "    \n",
    "    # Return average embedding\n",
    "    return avg_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = loadModel('arcface_weights.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all the file paths : minimu of 10 or count of images per person.\n",
    "filepaths = [np.random.choice(glob(root_path + name + '/*'), size=min(10, len(glob(root_path + name + '/*'))), replace=False) for name in dir_names]\n",
    "\n",
    "# Create data base\n",
    "database = {name:generate_avg_embedding(paths, model=model) for paths, name in tqdm(zip(filepaths, person_names), desc=\"Generating embedding\")}\n",
    "\n",
    "\n",
    "# Save database to disk\n",
    "np.save(\"database.npy\", database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load database from disk\n",
    "database = np.load(\"database.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Face Recognition**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_embeddings(embedding_1: np.ndarray, embedding_2: np.ndarray, threshold: float = 0.8) -> int:\n",
    "    # Calculate the distance between the embeddings\n",
    "    embedding_distance = embedding_1 - embedding_2\n",
    "\n",
    "    # Calculate the L2 norm of the distance vector\n",
    "    embedding_distance_norm = np.linalg.norm(embedding_distance)\n",
    "\n",
    "    # Return 1 if the distance is less than the threshold, else 0\n",
    "    return embedding_distance_norm if embedding_distance_norm < threshold else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_face(image: np.ndarray, database: dict, threshold: float = 1.0, model = model) -> str:\n",
    "    # Generate embedding for the new image\n",
    "    image_emb = image_to_embedding(image, model)\n",
    "    \n",
    "    # Clear output\n",
    "    # cls()\n",
    "    \n",
    "    # Store distances\n",
    "    distances = []\n",
    "    names = []\n",
    "    \n",
    "    # Loop over database\n",
    "    for name, embed in database.items():\n",
    "        \n",
    "        # Compare the embeddings\n",
    "        dist = compare_embeddings(embed, image_emb, threshold=threshold)\n",
    "\n",
    "        if dist > 0:\n",
    "            # Append the score\n",
    "            distances.append(dist)\n",
    "            names.append(name)\n",
    "\n",
    "    # Select the min distance\n",
    "    if distances:\n",
    "        min_dist = min(distances)\n",
    "        # print(distances)\n",
    "        return names[distances.index(min_dist)].title().strip(), 1 - min_dist\n",
    "    \n",
    "    return \"No Match Found\", 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "def extract_face(image):\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the image\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    \n",
    "    # Extract the face region\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = image[y:y+h, x:x+w]\n",
    "\n",
    "        # Resize the face to 100x100\n",
    "        resized_face = cv.resize(face, (112, 112))\n",
    "        return resized_face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Web Scraping**\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def download_image(base_url, url, folder, filename):\n",
    "    try:\n",
    "        # Construct the complete URL\n",
    "        complete_url = urljoin(base_url, url)\n",
    "\n",
    "        image_data = requests.get(complete_url).content\n",
    "        with open(os.path.join(folder, f\"{filename}.jpg\"), 'wb') as handler:\n",
    "            handler.write(image_data)\n",
    "        return os.path.join(folder, f\"{filename}.jpg\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def scrape_images(url, output_folder):\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find all img tags in the HTML\n",
    "    img_tags = soup.find_all('img')\n",
    "\n",
    "    # Download and save each image\n",
    "    for i, img_tag in enumerate(tqdm(img_tags)):\n",
    "        img_url = img_tag['src']\n",
    "        image_path = download_image(url, img_url, output_folder, f\"image_{i + 1}\")\n",
    "\n",
    "        # Print the path to the downloaded image\n",
    "        if image_path:\n",
    "            print(f\"Image {i + 1} saved at {image_path}\")\n",
    "\n",
    "# Example usage\n",
    "website_url = 'https://publications.iitm.ac.in/unit/department/department-of-computer-science-and-engineering/profiles'\n",
    "output_folder = 'output_images1'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "scrape_images(website_url, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predicting and displaying results**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images from datasets/test folder\n",
    "test_folder = \"TPA2_Face_Recognition-20231127T102046Z-001/TPA2_Face_Recognition/\"\n",
    "test_images = []\n",
    "for filename in os.listdir(test_folder):\n",
    "    \n",
    "    # Read the image and convert to RGB\n",
    "    img = cv.imread(os.path.join(test_folder, filename))\n",
    "    if img is None:\n",
    "        continue\n",
    "    \n",
    "    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "\n",
    "    if img is not None:\n",
    "        test_images.append(img)\n",
    "\n",
    "\n",
    "print(\"Number of test images loaded: \", len(test_images))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(30, 20))\n",
    "# rows = 5\n",
    "\n",
    "faces = []\n",
    "predicted_names = []\n",
    "confidence_scores = []\n",
    "\n",
    "for i, img in enumerate(tqdm(test_images)):\n",
    "    # Extract the face and resize it to 112x112\n",
    "    resized_face = extract_face(img)\n",
    "    if resized_face is None:\n",
    "        continue\n",
    "    resized_face = cv.resize(resized_face, (IMG_W, IMG_H))\n",
    "    # resized_face = cv.cvtColor(resized_face, cv.COLOR_BGR2RGB)\n",
    "    resized_face = resized_face.astype(np.float32)/255.0\n",
    "\n",
    "    # Recognize the face in the image\n",
    "    title, confidence = recognize_face(resized_face, database)\n",
    "    # print(str(confidence * 100))\n",
    "    faces.append((resized_face * 255.0).astype(np.uint8))\n",
    "    predicted_names.append(title)\n",
    "    confidence_scores.append(str(round(confidence * 100, 2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = 3\n",
    "rows = len(predicted_names) + 1\n",
    "\n",
    "# Calculate figure size from image sizes\n",
    "fig_width = 12\n",
    "fig_height = rows * fig_width * 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(fig_width, fig_height))\n",
    "i = 0\n",
    "\n",
    "# PLot the above images in table \n",
    "for y in tqdm(range(len(faces))):\n",
    "    # face = cv.cvtColor(faces[y], cv.COLOR_BGR2RGB)\n",
    "    # Plot the images\n",
    "    fig.add_subplot(rows, columns, i + 1)\n",
    "    plt.imshow(faces[y])\n",
    "    if i == 0:\n",
    "        plt.title(\"Face\", fontsize=10, pad=20)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Plot the names\n",
    "    fig.add_subplot(rows, columns, i + 2)\n",
    "    blank_image = np.ones((112, 280, 3), np.uint8) * 255\n",
    "    cv.putText(blank_image, predicted_names[y], (0, 50), cv.FONT_HERSHEY_SIMPLEX, 0.6, (25, 25, 25), 1)\n",
    "    plt.imshow(blank_image)\n",
    "    if i == 0:\n",
    "        plt.title(\"Predicted Name\", fontsize=10, pad=20)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Plot the scores\n",
    "    fig.add_subplot(rows, columns, i + 3)\n",
    "    blank_image = np.ones((112, 112, 3), np.uint8) * 255\n",
    "    cv.putText(blank_image, str(confidence_scores[y]), (0, 50), cv.FONT_HERSHEY_SIMPLEX, 0.6, (25, 25, 25), 1)\n",
    "    if i == 0:\n",
    "        plt.title(\"Confidence Score\", fontsize=10, pad=20)\n",
    "    plt.imshow(blank_image)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    i += 3\n",
    "\n",
    "ax.axis('off')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Testing on random samples**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# Randomly select an index\n",
    "index = np.random.randint(len(all_images))\n",
    "\n",
    "# Obtain an image and its corresponding label\n",
    "image_ = all_images[index]\n",
    "label_ = person_names[int(all_labels[index])]\n",
    "\n",
    "# Recognize the face in the image\n",
    "title, confidence = recognize_face(image_, database)\n",
    "\n",
    "# Plot the image along with its true and predicted labels\n",
    "plt.figure(figsize=(2, 2)) \n",
    "plt.imshow(image_)\n",
    "plt.title(f\"True:{label_}\\nPred:{title} {round(confidence * 100, 2)}%\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of images\n",
    "n_images = 100\n",
    "\n",
    "# Initialize the number of correct predictions\n",
    "n_correct = 0\n",
    "\n",
    "# Randomly Select images\n",
    "indicies = np.random.permutation(n_images)\n",
    "temp_images = all_images[indicies]\n",
    "temp_labels = all_labels[indicies]\n",
    "\n",
    "# Iterate over each image and its corresponding label\n",
    "for (image, label) in tqdm(zip(temp_images, temp_labels)):\n",
    "    \n",
    "    # Extract the true label of the person in the image\n",
    "    true_label = person_names[int(label)]\n",
    "\n",
    "    # Use the recognize_face function to predict the label of the person in the image\n",
    "    pred_label, _ = recognize_face(image, database)\n",
    "\n",
    "    # If the true label and the predicted label match, increment the number of correct predictions\n",
    "    # print(true_label.title(), pred_label)\n",
    "    if true_label.title() == pred_label:\n",
    "        n_correct += 1\n",
    "    else:\n",
    "        plt.figure(figsize=(2, 2))\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"True:{true_label}\\nPred:{pred_label}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "acc = (n_correct / n_images) * 100.0\n",
    "\n",
    "# Print the accuracy of the model\n",
    "print(f\"Model Accuracy: {acc}%!!!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 543939,
     "sourceId": 992580,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2988105,
     "sourceId": 5143137,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30407,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
